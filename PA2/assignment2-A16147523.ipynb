{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 DSC 102 2022 WI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment we will conduct data engineering for the Amazon dataset. It is divided into 2 parts. The extracted features in Part 1 will be used for the Part 2 of assignment, where you train a model (or models) to predict user ratings for a product.\n",
    "\n",
    "We will be using Apache Spark for this assignment. The default Spark API will be DataFrame, as it is now the recommended choice over the RDD API. That being said, please feel free to switch back to the RDD API if you see it as a better fit for the task. We provide you an option to request RDD format to start with. Also you can switch between DataFrame and RDD in your solution. \n",
    "\n",
    "Another newer API is Koalas, which is also avaliable. However, it has constraints and is not applicable to most tasks. Refer to the PA statement for detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the following parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T18:47:30.022030Z",
     "start_time": "2020-02-03T18:47:30.019499Z"
    }
   },
   "outputs": [],
   "source": [
    "PID = 'A16147523' # your pid, for instance: 'a43223333'\n",
    "INPUT_FORMAT = 'dataframe' # choose a format of your input data, valid options: 'dataframe', 'rdd', 'koalas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-03T18:50:16.780690Z",
     "start_time": "2020-02-03T18:47:30.263681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets ...Done\n"
     ]
    }
   ],
   "source": [
    "# Boiler plates, do NOT modify\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import getpass\n",
    "from pyspark.sql import SparkSession\n",
    "from utilities import SEED\n",
    "from utilities import PA2Test\n",
    "from utilities import PA2Data\n",
    "from utilities import data_cat\n",
    "from pa2_main import PA2Executor\n",
    "import time\n",
    "if INPUT_FORMAT == 'dataframe':\n",
    "    import pyspark.ml as M\n",
    "    import pyspark.sql.functions as F\n",
    "    import pyspark.sql.types as T\n",
    "if INPUT_FORMAT == 'koalas':\n",
    "    import databricks.koalas as ks\n",
    "elif INPUT_FORMAT == 'rdd':\n",
    "    import pyspark.mllib as M\n",
    "    from pyspark.mllib.feature import Word2Vec\n",
    "    from pyspark.mllib.linalg import Vectors\n",
    "    from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--py-files utilities.py,assignment2.py \\\n",
    "--deploy-mode client \\\n",
    "pyspark-shell'\n",
    "\n",
    "class args:\n",
    "    review_filename = data_cat.review_filename\n",
    "    product_filename = data_cat.product_filename\n",
    "    product_processed_filename = data_cat.product_processed_filename\n",
    "    ml_features_train_filename = data_cat.ml_features_train_filename\n",
    "    ml_features_test_filename = data_cat.ml_features_test_filename\n",
    "    output_root = '/home/{}/{}-pa2/test_results'.format(getpass.getuser(), PID)\n",
    "    test_results_root = data_cat.test_results_root\n",
    "    pid = PID\n",
    "\n",
    "pa2 = PA2Executor(args, input_format=INPUT_FORMAT)\n",
    "data_io = pa2.data_io\n",
    "data_dict = pa2.data_dict\n",
    "begin = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T20:45:52.353249Z",
     "start_time": "2020-01-26T20:45:52.343036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import your own dependencies\n",
    "import pyspark.ml.feature as K\n",
    "from pyspark.sql.functions import isnan\n",
    "#-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring the part_1 datasets to memory and de-cache part_2 datasets. \n",
    "# Execute this once before you start working on this Part\n",
    "data_dict, _ = data_io.cache_switch(data_dict, 'part_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Task0: warm up \n",
    "This task is provided for you to get familiar with Spark API. We will use the dataframe API to demonstrate. Solution is given to you and this task won't be graded.\n",
    "\n",
    "Refer to https://spark.apache.org/docs/latest/api/python/pyspark.sql.html for API guide.\n",
    "\n",
    "The task is to implement the function below. Given the ```product_data``` table:\n",
    "1. Take and print five rows.\n",
    "\n",
    "1. Select only the ```asin``` column, then print five rows of it.\n",
    "\n",
    "1. Select the row where ```asin = B00I8KEOTM``` and print it.\n",
    "\n",
    "1. Count the total number of rows.\n",
    "\n",
    "1. Calculate the mean ```price```.\n",
    "\n",
    "1. You need to conduct the above operations, then extract some statistics out of the generated columns. You need to put the statistics in a python dictionary named ```res```. The description and schema of it are as follows:\n",
    "    ```\n",
    "    res\n",
    "     | -- count_total: int -- count of total rows of the entire table after your operations\n",
    "     | -- mean_price: float -- mean value of column price\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T20:45:52.368918Z",
     "start_time": "2020-01-26T20:45:52.355018Z"
    }
   },
   "outputs": [],
   "source": [
    "def task_0(data_io, product_data):\n",
    "    # -----------------------------Column names--------------------------------\n",
    "    # Inputs:\n",
    "    asin_column = 'asin'\n",
    "    overall_column = 'overall'\n",
    "    # Outputs:\n",
    "    mean_rating_column = 'meanRating'\n",
    "    count_rating_column = 'countRating'\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "\n",
    "    product_data.show(5)\n",
    "    product_data[['asin']].show(5)\n",
    "    product_data.where(F.col('asin') == 'B00I8KEOTM').show()\n",
    "    count_rows = product_data.count()\n",
    "    mean_price = product_data.select(F.avg(F.col('price'))).head()[0]\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    # Calculate the values programmatically. Do not change the keys and do not\n",
    "    # hard-code values in the dict. Your submission will be evaluated with\n",
    "    # different inputs.\n",
    "    # Modify the values of the following dictionary accordingly.\n",
    "    res = {'count_total': None, 'mean_price': None}\n",
    "    \n",
    "    # Modify res:\n",
    "\n",
    "    res['count_total'] = count_rows\n",
    "    res['mean_price'] = mean_price\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-26T20:45:54.222111Z",
     "start_time": "2020-01-26T20:45:52.370377Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+-----+--------------------+\n",
      "|      asin|           salesRank|          categories|               title|price|             related|\n",
      "+----------+--------------------+--------------------+--------------------+-----+--------------------+\n",
      "|B00I8HVV6E|[Home &amp; Kitch...|[[Home & Kitchen,...|Intelligent Desig...|27.99|[also_viewed -> [...|\n",
      "|B00I8KEOTM|                null|[[Apps for Androi...|                null| null|[also_viewed -> [...|\n",
      "|B00I8KCW4G|[Clothing -> 2233...|[[Clothing, Shoes...|eShakti Women's P...|41.95|[also_viewed -> [...|\n",
      "|B00I8JKCQW|[Clothing -> 1405...|[[Clothing, Shoes...|Lady Slimming Mid...| null|[also_viewed -> [...|\n",
      "|B00I8JKI8E|[Home &amp; Kitch...|[[Clothing, Shoes...|3 Tier Bangle Bra...|24.99|[also_viewed -> [...|\n",
      "+----------+--------------------+--------------------+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+\n",
      "|      asin|\n",
      "+----------+\n",
      "|B00I8HVV6E|\n",
      "|B00I8KEOTM|\n",
      "|B00I8KCW4G|\n",
      "|B00I8JKCQW|\n",
      "|B00I8JKI8E|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+---------+--------------------+-----+-----+--------------------+\n",
      "|      asin|salesRank|          categories|title|price|             related|\n",
      "+----------+---------+--------------------+-----+-----+--------------------+\n",
      "|B00I8KEOTM|     null|[[Apps for Androi...| null| null|[also_viewed -> [...|\n",
      "+----------+---------+--------------------+-----+-----+--------------------+\n",
      "\n",
      "tests for task_0 --------------------------------------------------------------\n",
      "2/2 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if INPUT_FORMAT == 'dataframe':\n",
    "    res = task_0(data_io, data_dict['product'])\n",
    "    pa2.tests.test(res, 'task_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:30:44.034299Z",
     "start_time": "2019-12-10T21:30:44.012787Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load -s task_1 assignment2.py\n",
    "def task_1(data_io, review_data, product_data):\n",
    "    # -----------------------------Column names--------------------------------\n",
    "    # Inputs:\n",
    "    asin_column = 'asin'\n",
    "    overall_column = 'overall'\n",
    "    # Outputs:\n",
    "    mean_rating_column = 'meanRating'\n",
    "    count_rating_column = 'countRating'\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "    grouped = review_data.groupBy('asin').agg(F.avg('overall'), F.count('overall')).toDF('asin', 'meanRating', 'countRating')\n",
    "    transformed = product_data[['asin']].join(grouped, on='asin', how=\"left\")\n",
    "    count_total = transformed.count()\n",
    "    # print(count_total)\n",
    "    mean_meanRating = transformed.select(F.avg(F.col('meanRating'))).head()[0]\n",
    "    variance_meanRating = transformed.select(F.variance(F.col('meanRating'))).head()[0]\n",
    "    numNulls_meanRating = transformed.select([F.count(F.when(F.col('meanRating').isNull(), 'meanRating'))\n",
    "                                              .alias('meanRating')]).head()[0]\n",
    "    \n",
    "    mean_countRating = transformed.select(F.avg(F.col('countRating'))).head()[0]\n",
    "    variance_countRating = transformed.select(F.variance(F.col('countRating'))).head()[0]\n",
    "    numNulls_countRating = transformed.select([F.count(F.when(F.col('countRating').isNull(), 'countRating'))\n",
    "                                               .alias('countRating')]).head()[0]\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    # Calculate the values programmaticly. Do not change the keys and do not\n",
    "    # hard-code values in the dict. Your submission will be evaluated withVBc\n",
    "    # different inputs.\n",
    "    # Modify the values of the following dictionary accordingly.\n",
    "    res = {\n",
    "        'count_total': None,\n",
    "        'mean_meanRating': None,\n",
    "        'variance_meanRating': None,\n",
    "        'numNulls_meanRating': None,\n",
    "        'mean_countRating': None,\n",
    "        'variance_countRating': None,\n",
    "        'numNulls_countRating': None\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['count_total'] = count_total\n",
    "    res['mean_meanRating'] = mean_meanRating\n",
    "    res['variance_meanRating'] = variance_meanRating\n",
    "    res['numNulls_meanRating'] = numNulls_meanRating\n",
    "    res['mean_countRating'] = mean_countRating\n",
    "    res['variance_countRating'] = variance_countRating\n",
    "    res['numNulls_countRating'] = numNulls_countRating\n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_1')\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:19:04.214179Z",
     "start_time": "2019-12-09T22:18:39.293699Z"
    },
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_1 --------------------------------------------------------------\n",
      "Test 1/7 : count_total ... Pass\n",
      "Test 2/7 : mean_countRating ... Pass\n",
      "Test 3/7 : mean_meanRating ... Pass\n",
      "Test 4/7 : numNulls_countRating ... Pass\n",
      "Test 5/7 : numNulls_meanRating ... Pass\n",
      "Test 6/7 : variance_countRating ... Pass\n",
      "Test 7/7 : variance_meanRating ... Pass\n",
      "7/7 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_1(data_io, data_dict['review'], data_dict['product'])\n",
    "pa2.tests.test(res, 'task_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:31:16.942833Z",
     "start_time": "2019-12-10T21:31:16.925378Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load -s task_2 assignment2.py\n",
    "def task_2(data_io, product_data):\n",
    "    # -----------------------------Column names--------------------------------\n",
    "    # Inputs:\n",
    "    salesRank_column = 'salesRank'\n",
    "    categories_column = 'categories'\n",
    "    asin_column = 'asin'\n",
    "    # Outputs:\n",
    "    category_column = 'category'\n",
    "    bestSalesCategory_column = 'bestSalesCategory'\n",
    "    bestSalesRank_column = 'bestSalesRank'\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "    def flatten_cate(x):\n",
    "        if type(x) != list or len(x) == 0 or x[0][0] == \"\":\n",
    "            return None\n",
    "        return x[0][0]\n",
    "    \n",
    "    flatten_cate = F.udf(flatten_cate, T.StringType())\n",
    "    \n",
    "    cates = product_data.select(F.col('asin'), flatten_cate(F.col(\"categories\")).alias(category_column))#.toDF('asin', category_column)\n",
    "    ranks = product_data.select('asin', F.explode('salesRank')).toDF('asin', bestSalesCategory_column, bestSalesRank_column)\n",
    "    transformed = cates.join(ranks, on = 'asin', how = 'left')\n",
    "    \n",
    "#     transformed = product_data.select('asin', F.explode('salesRank')).toDF('asin', bestSalesCategory_column, bestSalesRank_column)\n",
    "#     transformed.show()\n",
    "#     categories_column = product_data.select(F.col('asin'), flatten_cate(F.col(\"categories\"))\n",
    "#                                             .alias(\"categories\")).toDF('asin', 'categories')\n",
    "    \n",
    "#     product_data.select('asin', F.explode('salesRank'))\n",
    "    \n",
    "#     def flatten_bestcate(x):\n",
    "#         if type(x) != dict or len(x) == 0:\n",
    "#             return None\n",
    "#         return list(x.keys())[0]\n",
    "    \n",
    "#     def flatten_rank(x):\n",
    "#         if type(x) != dict or len(x) == 0:\n",
    "#             return None\n",
    "#         return x[list(x.keys())[0]]\n",
    "    \n",
    "#     flatten_bestcate = F.udf(flatten_bestcate, T.StringType())\n",
    "#     flatten_rank = F.udf(flatten_rank, T.IntegerType())\n",
    "#     bestSalesCategory_column =  product_data.select(F.col('asin'), flatten_bestcate(F.col(\"salesRank\"))\n",
    "#                                                     .alias(\"bestSalesCategory\")).toDF('asin', 'bestSalesCategory')\n",
    "#     bestSalesRank_column = product_data.select(F.col('asin'), flatten_rank(F.col(\"salesRank\"))\n",
    "#                                                 .alias(\"bestSalesRank\")).toDF('asin', 'bestSalesRank')\n",
    "#     transformed = product_data[['asin']].join(categories_column, on='asin', how=\"left\") \\\n",
    "#                                        .join(bestSalesCategory_column, on='asin', how=\"left\") \\\n",
    "#                                         .join(bestSalesRank_column, on='asin', how=\"left\")\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    res = {\n",
    "        'count_total': None,\n",
    "        'mean_bestSalesRank': None,\n",
    "        'variance_bestSalesRank': None,\n",
    "        'numNulls_category': None,\n",
    "        'countDistinct_category': None,\n",
    "        'numNulls_bestSalesCategory': None,\n",
    "        'countDistinct_bestSalesCategory': None\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['count_total'] = transformed.count()\n",
    "    res['mean_bestSalesRank'] =  transformed.select(F.avg(F.col('bestSalesRank'))).head()[0]\n",
    "    res['variance_bestSalesRank'] = transformed.select(F.variance(F.col('bestSalesRank'))).head()[0]\n",
    "    res['numNulls_category'] = transformed.select([F.count(F.when(F.col(category_column).isNull(), category_column)).alias(category_column)]).head()[0]\n",
    "    res['countDistinct_category'] = transformed.select(F.countDistinct(category_column)).head()[0]\n",
    "    res['numNulls_bestSalesCategory'] = transformed.select([F.count(F.when(F.col('bestSalesCategory').isNull(), 'bestSalesCategory')).alias('bestSalesCategory')]).head()[0]\n",
    "    res['countDistinct_bestSalesCategory'] = transformed.select(F.countDistinct('bestSalesCategory')).head()[0]\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_2')\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:19:19.308187Z",
     "start_time": "2019-12-09T22:19:04.274345Z"
    },
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_2 --------------------------------------------------------------\n",
      "Test 1/7 : countDistinct_bestSalesCategory ... Pass\n",
      "Test 2/7 : countDistinct_category ... Pass\n",
      "Test 3/7 : count_total ... Pass\n",
      "Test 4/7 : mean_bestSalesRank ... Pass\n",
      "Test 5/7 : numNulls_bestSalesCategory ... Pass\n",
      "Test 6/7 : numNulls_category ... Pass\n",
      "Test 7/7 : variance_bestSalesRank ... Pass\n",
      "7/7 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_2(data_io, data_dict['product'])\n",
    "pa2.tests.test(res, 'task_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Task 3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:31:26.542481Z",
     "start_time": "2019-12-10T21:31:26.525050Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load -s task_3 assignment2.py\n",
    "def task_3(data_io, product_data):\n",
    "    # -----------------------------Column names--------------------------------\n",
    "    # Inputs:\n",
    "    asin_column = 'asin'\n",
    "    price_column = 'price'\n",
    "    attribute = 'also_viewed'\n",
    "    related_column = 'related'\n",
    "    # Outputs:\n",
    "    meanPriceAlsoViewed_column = 'meanPriceAlsoViewed'\n",
    "    countAlsoViewed_column = 'countAlsoViewed'\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "    \n",
    "    sub_data = product_data[['asin', 'price']]\n",
    "    \n",
    "    # count viewed\n",
    "    def get_length(x):\n",
    "        if type(x) != dict or 'also_viewed' not in x:\n",
    "            return None\n",
    "        return len(x['also_viewed'])\n",
    "    \n",
    "    get_len = F.udf(get_length, T.IntegerType())\n",
    "    df = product_data.select(F.col('asin'), get_len(F.col(\"related\")).alias(\"countAlsoViewed\"))\n",
    "    \n",
    "    mapping_data = product_data[['asin', 'price']]\n",
    "    sub_data = product_data[['asin', 'related']]\n",
    "    def get_lst(x):\n",
    "        if type(x) != dict or 'also_viewed' not in x or x['also_viewed'] == []:\n",
    "            return None\n",
    "        return x['also_viewed']\n",
    "    get_lst = F.udf(get_lst, T.ArrayType(T.StringType()))\n",
    "    converted_df = sub_data.select(F.col('asin'), get_lst(F.col(\"related\")).alias(\"extracted\"))\n",
    "    converted_df = converted_df.toDF('asin', 'extracted')#.show()\n",
    "    exploded_df = converted_df.select(F.col('asin').alias('benchmark'), F.explode(F.col(\"extracted\")).alias('asin'))\n",
    "    merged = exploded_df.join(mapping_data, on='asin', how=\"left\") # .groupBy('benchmark')\n",
    "    transformed = merged[['benchmark', 'price']].groupBy('benchmark').mean().toDF('asin', 'meanPriceAlsoViewed')\n",
    "    transformed = df.join(transformed, on='asin', how='left')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    res = {\n",
    "        'count_total': None,\n",
    "        'mean_meanPriceAlsoViewed': None,\n",
    "        'variance_meanPriceAlsoViewed': None,\n",
    "        'numNulls_meanPriceAlsoViewed': None,\n",
    "        'mean_countAlsoViewed': None,\n",
    "        'variance_countAlsoViewed': None,\n",
    "        'numNulls_countAlsoViewed': None\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['count_total'] = transformed.count()\n",
    "    res['mean_meanPriceAlsoViewed'] = transformed.select(F.avg(F.col('meanPriceAlsoViewed'))).head()[0]\n",
    "    res['variance_meanPriceAlsoViewed'] = transformed.select(F.variance(F.col('meanPriceAlsoViewed'))).head()[0]\n",
    "    res['numNulls_meanPriceAlsoViewed'] = transformed.select([F.count(F.when(F.col('meanPriceAlsoViewed').isNull(), 'meanPriceAlsoViewed')).alias('meanPriceAlsoViewed')]).head()[0]\n",
    "    res['mean_countAlsoViewed'] = transformed.select(F.avg(F.col('countAlsoViewed'))).head()[0]\n",
    "    res['variance_countAlsoViewed'] = transformed.select(F.variance(F.col('countAlsoViewed'))).head()[0]\n",
    "    res['numNulls_countAlsoViewed'] = transformed.select([F.count(F.when(F.col('countAlsoViewed').isNull(), 'countAlsoViewed')).alias('countAlsoViewed')]).head()[0]\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_3')\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:20:41.442745Z",
     "start_time": "2019-12-09T22:19:19.358780Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_3 --------------------------------------------------------------\n",
      "Test 1/7 : count_total ... Pass\n",
      "Test 2/7 : mean_countAlsoViewed ... Pass\n",
      "Test 3/7 : mean_meanPriceAlsoViewed ... Pass\n",
      "Test 4/7 : numNulls_countAlsoViewed ... Pass\n",
      "Test 5/7 : numNulls_meanPriceAlsoViewed ... Pass\n",
      "Test 6/7 : variance_countAlsoViewed ... Pass\n",
      "Test 7/7 : variance_meanPriceAlsoViewed ... Pass\n",
      "7/7 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_3(data_io, data_dict['product'])\n",
    "pa2.tests.test(res, 'task_3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:31:39.503390Z",
     "start_time": "2019-12-10T21:31:39.484724Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load -s task_4 assignment2.py\n",
    "def task_4(data_io, product_data):\n",
    "    # -----------------------------Column names--------------------------------\n",
    "    # Inputs:\n",
    "    price_column = 'price'\n",
    "    title_column = 'title'\n",
    "    # Outputs:\n",
    "    meanImputedPrice_column = 'meanImputedPrice'\n",
    "    medianImputedPrice_column = 'medianImputedPrice'\n",
    "    unknownImputedTitle_column = 'unknownImputedTitle'\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "\n",
    "    imputer = K.Imputer()\n",
    "    imputer.setInputCols([\"price\"])\n",
    "    imputer.setOutputCols([\"medianImputedPrice\"])\n",
    "    fit_median = imputer.setStrategy(\"median\").fit(product_data[['price']]).transform(product_data[['price']])\n",
    "    imputer.setOutputCols([\"meanImputedPrice\"])\n",
    "    fit_mean = imputer.setStrategy(\"mean\").fit(product_data[['price']]).transform(product_data[['price']])\n",
    "    title_df = product_data.select(F.col('title')).fillna('unknown').withColumnRenamed('title', 'unknownImputedTitle')#.show()\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    res = {\n",
    "        'count_total': None,\n",
    "        'mean_meanImputedPrice': None,\n",
    "        'variance_meanImputedPrice': None,\n",
    "        'numNulls_meanImputedPrice': None,\n",
    "        'mean_medianImputedPrice': None,\n",
    "        'variance_medianImputedPrice': None,\n",
    "        'numNulls_medianImputedPrice': None,\n",
    "        'numUnknowns_unknownImputedTitle': None\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['count_total'] = title_df.count()\n",
    "    res['mean_meanImputedPrice'] = fit_mean.select(F.avg(F.col('meanImputedPrice'))).head()[0]\n",
    "    res['variance_meanImputedPrice'] = fit_mean.select(F.variance(F.col('meanImputedPrice'))).head()[0]\n",
    "    res['numNulls_meanImputedPrice'] = fit_mean.select([F.count(F.when(F.col('meanImputedPrice').isNull(), 'meanImputedPrice')).alias('meanImputedPrice')]).head()[0]\n",
    "    res['mean_medianImputedPrice'] = fit_median.select(F.avg(F.col('medianImputedPrice'))).head()[0]\n",
    "    res['variance_medianImputedPrice'] = fit_median.select(F.variance(F.col('medianImputedPrice'))).head()[0]\n",
    "    res['numNulls_medianImputedPrice'] = fit_median.select([F.count(F.when(F.col('medianImputedPrice').isNull(), 'medianImputedPrice')).alias('medianImputedPrice')]).head()[0]\n",
    "    res['numUnknowns_unknownImputedTitle'] = title_df.filter(F.col(\"unknownImputedTitle\") == \"unknown\").count()\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_4')\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:20:47.953226Z",
     "start_time": "2019-12-09T22:20:41.523379Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_4 --------------------------------------------------------------\n",
      "Test 1/8 : count_total ... Pass\n",
      "Test 2/8 : mean_meanImputedPrice ... Pass\n",
      "Test 3/8 : mean_medianImputedPrice ... Pass\n",
      "Test 4/8 : numNulls_meanImputedPrice ... Pass\n",
      "Test 5/8 : numNulls_medianImputedPrice ... Pass\n",
      "Test 6/8 : numUnknowns_unknownImputedTitle ... Pass\n",
      "Test 7/8 : variance_meanImputedPrice ... Pass\n",
      "Test 8/8 : variance_medianImputedPrice ... Pass\n",
      "8/8 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_4(data_io, data_dict['product'])\n",
    "pa2.tests.test(res, 'task_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:32:29.284661Z",
     "start_time": "2019-12-10T21:32:29.267237Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load -s task_5 assignment2.py\n",
    "def task_5(data_io, product_processed_data, word_0, word_1, word_2):\n",
    "    # -----------------------------Column names--------------------------------\n",
    "    # Inputs:\n",
    "    title_column = 'title'\n",
    "    # Outputs:\n",
    "    titleArray_column = 'titleArray'\n",
    "    titleVector_column = 'titleVector'\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "    array_df = product_processed_data.select(F.split(F.lower(product_processed_data['title']), ' ').alias('titleArray')) # .show()\n",
    "    word2Vec = M.feature.Word2Vec(vectorSize = 16, minCount=100, seed=102, numPartitions = 4, inputCol = \"titleArray\", outputCol = \"titleVector\")\n",
    "    model = word2Vec.fit(array_df)\n",
    "    \n",
    "    product_processed_data_output = model.transform(array_df)#.count()\n",
    "#     size_vocabulary = model.getVectors().count()\n",
    "#     word_0_synonyms = model.findSynonymsArray(word_0, 10)\n",
    "#     word_1_synonyms = model.findSynonymsArray(word_1, 10)\n",
    "#     word_2_synonyms = model.findSynonymsArray(word_2, 10)\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    res = {\n",
    "        'count_total': None,\n",
    "        'size_vocabulary': None,\n",
    "        'word_0_synonyms': None,\n",
    "        'word_1_synonyms': None,\n",
    "        'word_2_synonyms': None\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['count_total'] = product_processed_data_output.count()\n",
    "    res['size_vocabulary'] = model.getVectors().count()\n",
    "    for name, word in zip(\n",
    "        ['word_0_synonyms', 'word_1_synonyms', 'word_2_synonyms'],\n",
    "        [word_0, word_1, word_2]\n",
    "    ):\n",
    "        res[name] = model.findSynonymsArray(word, 10)\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_5')\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:26:05.015529Z",
     "start_time": "2019-12-09T22:20:47.999834Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pyspark/sql/session.py:346: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
      "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_5 --------------------------------------------------------------\n",
      "Test 1/8 : count_total ... Pass\n",
      "Test 2/8 : size_vocabulary ... Pass\n",
      "Test 3/8 : word_0_synonyms-length ... Pass\n",
      "Test 4/8 : word_0_synonyms-correctness ... Pass\n",
      "Test 5/8 : word_1_synonyms-length ... Pass\n",
      "Test 6/8 : word_1_synonyms-correctness ... Pass\n",
      "Test 7/8 : word_2_synonyms-length ... Pass\n",
      "Test 8/8 : word_2_synonyms-correctness ... Pass\n",
      "5/5 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_5(data_io, data_dict['product_processed'], 'piano', 'rice', 'laptop')\n",
    "pa2.tests.test(res, 'task_5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T21:32:39.991460Z",
     "start_time": "2019-12-10T21:32:39.974136Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load -s task_6 assignment2.py\n",
    "def task_6(data_io, product_processed_data):\n",
    "    # -----------------------------Column names--------------------------------\n",
    "    # Inputs:\n",
    "    category_column = 'category'\n",
    "    # Outputs:\n",
    "    categoryIndex_column = 'categoryIndex'\n",
    "    categoryOneHot_column = 'categoryOneHot'\n",
    "    categoryPCA_column = 'categoryPCA'\n",
    "    # -------------------------------------------------------------------------    \n",
    "\n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "    \n",
    "    sub = product_processed_data[[category_column]]\n",
    "    string_indexer = K.StringIndexer(inputCol = category_column, outputCol = categoryIndex_column)\n",
    "    string_indexer_model = string_indexer.fit(sub)\n",
    "    indexed_df = string_indexer_model.transform(sub)#.show()\n",
    "    encoder = K.OneHotEncoderEstimator(inputCols = [categoryIndex_column], outputCols = [categoryOneHot_column], dropLast=False)\n",
    "    encoded_df = encoder.fit(indexed_df).transform(indexed_df)\n",
    "    pca = K.PCA(k=15, inputCol=categoryOneHot_column, outputCol=categoryPCA_column)\n",
    "    result_df = pca.fit(encoded_df).transform(encoded_df)\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    res = {\n",
    "        'count_total': None,\n",
    "        'meanVector_categoryOneHot': [None, ],\n",
    "        'meanVector_categoryPCA': [None, ]\n",
    "    }\n",
    "    # Modify res:\n",
    "    count_total = result_df.count()\n",
    "    meanVector_categoryOneHot = result_df.select(M.stat.Summarizer.mean(result_df[categoryOneHot_column])).head()[0]\n",
    "    meanVector_categoryPCA = result_df.select(M.stat.Summarizer.mean(result_df[categoryPCA_column])).head()[0]\n",
    "    \n",
    "    res['count_total'] = count_total\n",
    "    res['meanVector_categoryOneHot'] = meanVector_categoryOneHot\n",
    "    res['meanVector_categoryPCA'] = meanVector_categoryPCA\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_6')\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T22:29:57.717617Z",
     "start_time": "2019-12-09T22:29:51.132434Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_6 --------------------------------------------------------------\n",
      "Test 1/9 : count_total ... Pass\n",
      "Test 2/9 : meanVector_categoryOneHot-length ... Pass\n",
      "Test 3/9 : meanVector_categoryOneHot-sum ... Pass\n",
      "Test 4/9 : meanVector_categoryOneHot-mean ... Pass\n",
      "Test 5/9 : meanVector_categoryOneHot-variance ... Pass\n",
      "Test 6/9 : meanVector_categoryPCA-length ... Pass\n",
      "Test 7/9 : meanVector_categoryPCA-sum ... Pass\n",
      "Test 8/9 : meanVector_categoryPCA-mean ... Pass\n",
      "Test 9/9 : meanVector_categoryPCA-variance ... Pass\n",
      "9/9 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_6(data_io, data_dict['product_processed'])\n",
    "pa2.tests.test(res, 'task_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T21:23:18.882119Z",
     "start_time": "2019-11-26T21:23:18.873162Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End to end time: 5728.93918299675\n"
     ]
    }
   ],
   "source": [
    "print (\"End to end time: {}\".format(time.time()-begin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring the part_2 datasets to memory and de-cache part_1 datasets.\n",
    "# Execute this once before you start working on this Part\n",
    "data_dict, _ = data_io.cache_switch(data_dict, 'part_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_7(data_io, train_data, test_data):\n",
    "    \n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "    \n",
    "    rf = M.regression.RandomForestRegressor(maxDepth=5).setLabelCol(\"overall\").setFeaturesCol(\"features\")\n",
    "    mdl = rf.fit(train_data)\n",
    "    preds_df = mdl.transform(test_data)\n",
    "    metrics = M.evaluation.RegressionEvaluator(predictionCol = \"overall\", labelCol = \"prediction\", metricName='rmse')\n",
    "    test_rmse = metrics.evaluate(preds_df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    res = {\n",
    "        'test_rmse': None\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['test_rmse'] = test_rmse\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_7')\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pyspark/sql/session.py:346: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
      "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_7 --------------------------------------------------------------\n",
      "Test 1/1 : test_rmse ... Pass\n",
      "1/1 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_7(data_io, data_dict['ml_features_train'], data_dict['ml_features_test'])\n",
    "pa2.tests.test(res, 'task_7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_8(data_io, train_data, test_data):\n",
    "    \n",
    "    # ---------------------- Your implementation begins------------------------\n",
    "    \n",
    "    train, val = train_data.randomSplit(weights=[0.75, 0.25], seed=102)\n",
    "\n",
    "    depths = [5, 7, 9, 12]\n",
    "    candidates = []\n",
    "    for depth in depths:\n",
    "        rf = M.regression.RandomForestRegressor(maxDepth=depth).setLabelCol(\"overall\").setFeaturesCol(\"features\")\n",
    "        mdl = rf.fit(train)\n",
    "        preds_df = mdl.transform(val)\n",
    "        metrics = M.evaluation.RegressionEvaluator(predictionCol = \"overall\", labelCol = \"prediction\", metricName='rmse')\n",
    "        val_rmse = metrics.evaluate(preds_df)\n",
    "        candidates.append((val_rmse, mdl))\n",
    "\n",
    "    val_rmses = [i[0] for i in candidates]\n",
    "    valid_rmse_depth_5 = val_rmses[0]\n",
    "    valid_rmse_depth_7 = val_rmses[1]\n",
    "    valid_rmse_depth_9 = val_rmses[2]\n",
    "    valid_rmse_depth_12 = val_rmses[3]\n",
    "\n",
    "    best_mdl = min(candidates, key=lambda x:x[0])[1]\n",
    "    final_pred = best_mdl.transform(test_data)\n",
    "    metrics = M.evaluation.RegressionEvaluator(predictionCol = \"overall\", labelCol = \"prediction\", metricName='rmse')\n",
    "    test_rmse = metrics.evaluate(final_pred)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # ---------------------- Put results in res dict --------------------------\n",
    "    res = {\n",
    "        'test_rmse': None,\n",
    "        'valid_rmse_depth_5': None,\n",
    "        'valid_rmse_depth_7': None,\n",
    "        'valid_rmse_depth_9': None,\n",
    "        'valid_rmse_depth_12': None,\n",
    "    }\n",
    "    # Modify res:\n",
    "    res['test_rmse'] = test_rmse\n",
    "    res['valid_rmse_depth_5'] = valid_rmse_depth_5\n",
    "    res['valid_rmse_depth_7'] = valid_rmse_depth_7\n",
    "    res['valid_rmse_depth_9'] = valid_rmse_depth_9\n",
    "    res['valid_rmse_depth_12'] = valid_rmse_depth_12\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------- Do not change -----------------------------\n",
    "    data_io.save(res, 'task_8')\n",
    "    return res\n",
    "    # -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pyspark/sql/session.py:346: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead\n",
      "  warnings.warn(\"inferring schema from dict is deprecated,\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests for task_8 --------------------------------------------------------------\n",
      "Test 1/5 : test_rmse ... Pass\n",
      "Test 2/5 : valid_rmse_depth_12 ... Pass\n",
      "Test 3/5 : valid_rmse_depth_5 ... Pass\n",
      "Test 4/5 : valid_rmse_depth_7 ... Pass\n",
      "Test 5/5 : valid_rmse_depth_9 ... Pass\n",
      "5/5 passed\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = task_8(data_io, data_dict['ml_features_train'], data_dict['ml_features_test'])\n",
    "pa2.tests.test(res, 'task_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End to end time: 1528.9998021125793\n"
     ]
    }
   ],
   "source": [
    "print (\"End to end time: {}\".format(time.time()-begin))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
